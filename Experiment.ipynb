{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QYfN4zarJcYZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import spectral_embedding, SpectralEmbedding\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, ndcg_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L \"https://www.dropbox.com/scl/fi/8ba6yivfqember870awen/Video_Games_5.json.gz?rlkey=y8l7biii4mhc71os9eezespxo&st=7jiqtj4n&dl=1\" -o data/Video_Games_5.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Z6r9iOUJ9GC"
   },
   "source": [
    "# 1. Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jnDy9iwKUlN"
   },
   "outputs": [],
   "source": [
    "def load_dataset(path, sep=',', skiprows=0):\n",
    "    \"\"\"Загружает датасеты\"\"\"\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        sep=sep,\n",
    "        names=['user_id', 'item_id', 'rating', 'timestamp'],\n",
    "        skiprows=skiprows\n",
    "    )\n",
    "    return df[['user_id', 'item_id', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2pHsPvECMWit"
   },
   "outputs": [],
   "source": [
    "def load_dataset_json(path):\n",
    "    \"\"\"Загружает датасеты формата json\"\"\"\n",
    "    import gzip\n",
    "    import json\n",
    "\n",
    "    def parse(path):\n",
    "      g = gzip.open(path, 'rb')\n",
    "      for l in g:\n",
    "        yield json.loads(l)\n",
    "\n",
    "    def getDF(path):\n",
    "      i = 0\n",
    "      df = {}\n",
    "      for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "      return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "    df = getDF(path)[['reviewerID', 'asin', 'overall']].rename(columns={'reviewerID': 'user_id', 'asin': 'item_id', 'overall': 'rating'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rfsx2Tz5J8Hk"
   },
   "outputs": [],
   "source": [
    "def build_user_item_matrix(df):\n",
    "    \"\"\"Строит матрицу взаимодействий (users × items).\"\"\"\n",
    "    R = df.pivot_table(\n",
    "        index='user_id', columns='item_id', values='rating', fill_value=0\n",
    "    )\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQh6CwnXNNy7"
   },
   "outputs": [],
   "source": [
    "def split_train_test_matrix(R, test_size=0.2, random_state=42):\n",
    "    \"\"\"Случайное разделение взаимодействий на train/test.\"\"\"\n",
    "    df.columns = ['user_id', 'item_id', 'rating']\n",
    "    train_df, test_df = train_test_split(df, test_size=test_size, random_state=random_state)\n",
    "    R_train = build_user_item_matrix(train_df)\n",
    "    return R_train, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82Ynz_F2KHsg"
   },
   "source": [
    "# 2. Базовые методы CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AjbeoYbOKS4E"
   },
   "outputs": [],
   "source": [
    "def user_based_cf_predict(R_train):\n",
    "    \"\"\"User-based CF: взвешенная сумма по cosine similarity.\"\"\"\n",
    "    S = cosine_similarity(R_train)\n",
    "    # нормализация по сумме абсолютных весов\n",
    "    denom = np.abs(S).sum(axis=1, keepdims=True)\n",
    "    P = S.dot(R_train.values) / denom\n",
    "    return pd.DataFrame(P, index=R_train.index, columns=R_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ay42lc3oJEQm"
   },
   "outputs": [],
   "source": [
    "def item_based_cf_predict(R_train):\n",
    "    \"\"\"Item-based CF по аналогии.\"\"\"\n",
    "    S_item = cosine_similarity(R_train.T)\n",
    "    denom = np.abs(S_item).sum(axis=1, keepdims=True)\n",
    "    P = R_train.values.dot(S_item) / denom.T\n",
    "    return pd.DataFrame(P, index=R_train.index, columns=R_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2vmxqZHKaFX"
   },
   "source": [
    "# 3. Матричная факторизация (NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-RyBsx2SJZds"
   },
   "outputs": [],
   "source": [
    "def nmf_predict(R_train, n_components=20, random_state=42):\n",
    "    \"\"\"Аппроксимирует R_train через NMF, возвращает полную матрицу предсказаний.\"\"\"\n",
    "    model = NMF(n_components=n_components, init='random', random_state=random_state, max_iter=300)\n",
    "    U = model.fit_transform(R_train.values)\n",
    "    V = model.components_\n",
    "    P = U.dot(V)\n",
    "    return pd.DataFrame(P, index=R_train.index, columns=R_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpwGJhXoKgv2"
   },
   "source": [
    "# 4. Спектральная кластеризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iva9ccHVKedo"
   },
   "outputs": [],
   "source": [
    "def spectral_clustering_predict(R_train, n_clusters=20, embed_dim=20, random_state=42):\n",
    "    \"\"\"Строит граф сходств и использует spectral embedding + k-means для рекомендаций.\"\"\"\n",
    "    # матрица сходств пользователей\n",
    "    A = cosine_similarity(R_train)\n",
    "    # спектральные эмбеддинги\n",
    "    embedding = spectral_embedding(A, n_components=embed_dim, random_state=random_state)\n",
    "    # кластеризация k-means\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state)\n",
    "    labels = kmeans.fit_predict(embedding)\n",
    "    # для каждого юзера средний рейтинг внутри кластера\n",
    "    R = R_train.copy()\n",
    "    R['cluster'] = labels\n",
    "    preds = np.zeros_like(R_train.values, dtype=float)\n",
    "    for c in np.unique(labels):\n",
    "        idx = np.where(labels == c)[0]\n",
    "        cluster_mean = R_train.values[idx].mean(axis=0)\n",
    "        preds[idx] = cluster_mean\n",
    "    return pd.DataFrame(preds, index=R_train.index, columns=R_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fu7VmaFQwFWO"
   },
   "outputs": [],
   "source": [
    "def spectral_clustering_knn_predict(R_train, n_clusters=20, embed_dim=20, n_neighbors=5, random_state=42):\n",
    "    \"\"\"Строит граф сходств и использует spectral embedding with knn + k-means для рекомендаций.\"\"\"\n",
    "    # матрица сходств пользователей\n",
    "    se = SpectralEmbedding(\n",
    "        n_components=embed_dim,\n",
    "        affinity='nearest_neighbors',\n",
    "        n_neighbors=n_neighbors)\n",
    "    # спектральные эмбеддинги\n",
    "    embedding = se.fit_transform(R_train.values)\n",
    "    # кластеризация k-means\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state)\n",
    "    labels = kmeans.fit_predict(embedding)\n",
    "    # для каждого юзера средний рейтинг внутри кластера\n",
    "    R = R_train.copy()\n",
    "    R['cluster'] = labels\n",
    "    preds = np.zeros_like(R_train.values, dtype=float)\n",
    "    for c in np.unique(labels):\n",
    "        idx = np.where(labels == c)[0]\n",
    "        cluster_mean = R_train.values[idx].mean(axis=0)\n",
    "        preds[idx] = cluster_mean\n",
    "    return pd.DataFrame(preds, index=R_train.index, columns=R_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Gzir8diKkUt"
   },
   "source": [
    "# 5. Гибридный метод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CkiPSEV0Kl8-"
   },
   "outputs": [],
   "source": [
    "def hybrid_predict(P_spec, P_nmf, alpha=0.5):\n",
    "    \"\"\"Гибридизация: взвешенное среднее спектральных и NMF предсказаний.\"\"\"\n",
    "    return alpha * P_spec + (1 - alpha) * P_nmf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgcMxKusL9py"
   },
   "source": [
    "# 6. Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dEMvnz06MFeB"
   },
   "outputs": [],
   "source": [
    "def tune_nmf_components(R_train, R_test, comps):\n",
    "    \"\"\"Подбор гиперпараметров в NMF\"\"\"\n",
    "    best, best_rmse = None, np.inf\n",
    "    for c in tqdm(comps):\n",
    "        P = nmf_predict(R_train, n_components=c)\n",
    "        rmse = evaluate_regression(P, R_test)['RMSE']\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse, best = rmse, c\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pARTCFDnMHeE"
   },
   "outputs": [],
   "source": [
    "def tune_spectral_params(R_train, R_test, clusters, embeds):\n",
    "    \"\"\"Подбор гиперпараметров в спектральной кластеризации с cosine_similarity\"\"\"\n",
    "    best, best_rmse = (None, None), np.inf\n",
    "    for nc in tqdm(clusters):\n",
    "        for ed in embeds:\n",
    "            P = spectral_clustering_predict(R_train, n_clusters=nc, embed_dim=ed)\n",
    "            rmse = evaluate_regression(P, R_test)['RMSE']\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse, best = rmse, (nc, ed)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v_EInHKICOJ1"
   },
   "outputs": [],
   "source": [
    "def tune_spectral_knn_params(R_train, R_test, n_neighbors_lst, n_clusters=20, embed_dim=20):\n",
    "    \"\"\"Подбор гиперпараметров в спектральной кластеризации с knn\"\"\"\n",
    "    best, best_rmse = None, np.inf\n",
    "    for n in tqdm(n_neighbors_lst):\n",
    "        P = spectral_clustering_knn_predict(R_train, n_clusters=n_clusters, embed_dim=embed_dim, n_neighbors=n)\n",
    "        rmse = evaluate_regression(P, R_test)['RMSE']\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse, best = rmse, n\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lBnRloRtL7Va"
   },
   "outputs": [],
   "source": [
    "def tune_hybrid_alpha(P_spec, P_nmf, R_test, alphas):\n",
    "    \"\"\"Подбор гиперпараметров в гибридной модели\"\"\"\n",
    "    best, best_rmse = None, np.inf\n",
    "    for a in tqdm(alphas):\n",
    "        P = hybrid_predict(P_spec, P_nmf, alpha=a)\n",
    "        rmse = evaluate_regression(P, R_test)['RMSE']\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse, best = rmse, a\n",
    "    return best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7O75_kiKosE"
   },
   "source": [
    "# 7. Метрики оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z0kGwLS8KnZi"
   },
   "outputs": [],
   "source": [
    "def evaluate_regression(P, R_test):\n",
    "    \"\"\"RMSE и MAE по тестовым точечным наблюдениям.\"\"\"\n",
    "    y_true = R_test['rating'].values\n",
    "    y_pred = [\n",
    "        P.loc[u, i] if (u in P.index and i in P.columns) else np.nan\n",
    "        for u, i in zip(R_test['user_id'], R_test['item_id'])\n",
    "    ]\n",
    "    mask = ~np.isnan(y_pred)\n",
    "    return {\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true[mask], np.array(y_pred)[mask])),\n",
    "        'MAE' : mean_absolute_error(y_true[mask], np.array(y_pred)[mask])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IxN9YiIlKqww"
   },
   "outputs": [],
   "source": [
    "def evaluate_ranking(P, R_train, R_test, k=10):\n",
    "    \"\"\"Precision@k, Recall@k, NDCG@k, Coverage.\"\"\"\n",
    "    # формируем релевантности в тесте (rating >= 4)\n",
    "    rel = R_test[R_test['rating'] >= 4].groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "    precisions, recalls, ndcgs = [], [], []\n",
    "    recommended_items = set()\n",
    "    for u in P.index:\n",
    "        # исключаем уже оцененные в train\n",
    "        seen = set(R_train.loc[u][R_train.loc[u] > 0].index)\n",
    "        preds_u = P.loc[u].drop(labels=seen)\n",
    "        top_k = preds_u.nlargest(k).index.tolist()\n",
    "        recommended_items.update(top_k)\n",
    "        true_set = rel.get(u, set())\n",
    "        hits = len(set(top_k) & true_set)\n",
    "        precisions.append(hits / k)\n",
    "        recalls.append(hits / (len(true_set) or 1))\n",
    "        # NDCG\n",
    "        y_true = [1 if item in true_set else 0 for item in top_k]\n",
    "        y_score = [preds_u[item] for item in top_k]\n",
    "        ndcgs.append(ndcg_score([y_true], [y_score]))\n",
    "    coverage = len(recommended_items) / R_train.shape[1]\n",
    "    return {\n",
    "        'Precision@10': np.mean(precisions),\n",
    "        'Recall@10'   : np.mean(recalls),\n",
    "        'NDCG@10'     : np.mean(ndcgs),\n",
    "        'Coverage'    : coverage\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yGgf7MoMz3F"
   },
   "source": [
    "# 8. Эксперимент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y4qYCjgaPBw_"
   },
   "outputs": [],
   "source": [
    "dataset_loaders = {\n",
    "    'AmazonArtsCraftsAndSewing': lambda: load_dataset_json('./data/Arts_Crafts_and_Sewing_5.json.gz'),\n",
    "    'AmazonDigitalMusic': lambda: load_dataset_json('./data/Digital_Music_5.json.gz'),\n",
    "    'AmazonVideoGames': lambda: load_dataset_json('./data/Video_Games_5.json.gz'),\n",
    "    'MovieLens1M': lambda: load_dataset(path='./data/MovieLens1M.dat', sep='::'),\n",
    "}\n",
    "\n",
    "final_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ydf9uMTQJaqU"
   },
   "outputs": [],
   "source": [
    "for name, loader in tqdm(dataset_loaders.items()):\n",
    "    df = loader()\n",
    "    R_train, R_test = split_train_test_matrix(build_user_item_matrix(df), test_size=0.2)\n",
    "\n",
    "    # Проверка разреженности\n",
    "    num_users, num_items = R_train.shape\n",
    "    nonzeros = (R_train > 0).sum().sum()\n",
    "    sparsity = 1 - nonzeros / (num_users * num_items)\n",
    "    print(f\"Dataset {name}: sparsity = {sparsity:.4f}\")\n",
    "\n",
    "    # Подбор гиперпараметров\n",
    "    best_nmf = tune_nmf_components(R_train, R_test, comps=[10, 20, 50])\n",
    "    best_spec = tune_spectral_params(R_train, R_test, clusters=[10, 20, 50], embeds=[5, 10, 15, 25, 50])\n",
    "    best_n_neighbors = tune_spectral_knn_params(R_train, R_test, n_neighbors_lst=[5, 10, 20], n_clusters=best_spec[0], embed_dim=best_spec[1])\n",
    "\n",
    "    # Обучение моделей\n",
    "    P_user     = user_based_cf_predict(R_train)\n",
    "    P_item     = item_based_cf_predict(R_train)\n",
    "    P_nmf      = nmf_predict(R_train, n_components=best_nmf)\n",
    "    P_spec     = spectral_clustering_predict(R_train, n_clusters=best_spec[0], embed_dim=best_spec[1])\n",
    "    P_spec_knn = spectral_clustering_knn_predict(R_train, n_clusters=best_spec[0], embed_dim=best_spec[1], n_neighbors=best_n_neighbors)\n",
    "\n",
    "    best_alpha = tune_hybrid_alpha(P_spec, P_nmf, R_test, alphas=[0.3, 0.4, 0.5])\n",
    "    P_hyb      = hybrid_predict(P_spec, P_nmf, alpha=best_alpha)\n",
    "    best_alpha = tune_hybrid_alpha(P_spec_knn, P_nmf, R_test, alphas=[0.3, 0.4, 0.5])\n",
    "    P_hyb_knn  = hybrid_predict(P_spec_knn, P_nmf, alpha=best_alpha)\n",
    "\n",
    "    methods = {\n",
    "        'User-CF'     : P_user,\n",
    "        'Item-CF'     : P_item,\n",
    "        'NMF'         : P_nmf,\n",
    "        'Spectral_cos': P_spec,\n",
    "        'Spectral_KNN': P_spec_knn,\n",
    "        'Hybrid_cos'  : P_hyb,\n",
    "        'Hybrid_KNN'  : P_hyb_knn,\n",
    "    }\n",
    "\n",
    "    for method, P_std in tqdm(methods.items()):\n",
    "        reg = evaluate_regression(P_std, R_test)\n",
    "        rank = evaluate_ranking(P_std, R_train, R_test)\n",
    "\n",
    "        row = {\n",
    "            'Dataset'     : name,\n",
    "            'Method'      : method,\n",
    "            'RMSE'        : reg['RMSE'],\n",
    "            'MAE'         : reg['MAE'],\n",
    "            'Precision@10': rank['Precision@10'],\n",
    "            'Recall@10'   : rank['Recall@10'],\n",
    "            'NDCG@10'     : rank['NDCG@10'],\n",
    "            'Coverage'    : rank['Coverage'],\n",
    "        }\n",
    "        final_results.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xL1EAOjMx2Bw"
   },
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(final_results).set_index(['Dataset', 'Method'])\n",
    "print(\"Final comparison table:\")\n",
    "display(final_df)\n",
    "final_df.to_csv('./results/final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCoTvgcovedY"
   },
   "source": [
    "# 9. Анализ зависимости качества от размерности эмбеддингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uAH-y_47vc4Z"
   },
   "outputs": [],
   "source": [
    "# рассмотрим зависимость в датасете 'MovieLens1M'\n",
    "df = dataset_loaders['MovieLens1M']()\n",
    "R_train, R_test = split_train_test_matrix(build_user_item_matrix(df), test_size=0.2)\n",
    "\n",
    "# наилучшее качество при n_clusters == 50, поэтому фиксируем его\n",
    "for ed in tqdm([2, 5, 7, 10, 15, 25, 40, 50, 75, 100]):\n",
    "    P_std = spectral_clustering_predict(R_train, n_clusters=50, embed_dim=ed)\n",
    "    reg = evaluate_regression(P_std, R_test)\n",
    "    rank = evaluate_ranking(P_std, R_train, R_test)\n",
    "\n",
    "    row = {\n",
    "        'Embed_dim'   : ed,\n",
    "        'RMSE'        : reg['RMSE'],\n",
    "        'MAE'         : reg['MAE'],\n",
    "        'Precision@10': rank['Precision@10'],\n",
    "        'Recall@10'   : rank['Recall@10'],\n",
    "        'NDCG@10'     : rank['NDCG@10'],\n",
    "        'Coverage'    : rank['Coverage'],\n",
    "    }\n",
    "    final_results.append(row)\n",
    "\n",
    "final_df = pd.DataFrame(final_results).set_index('Embed_dim')\n",
    "final_df.to_csv('./results/embed_dim.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Тест визуала"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv('./data/movies.dat', sep='::', names=['item_id', 'title', 'genre'])\n",
    "df = dataset_loaders['MovieLens1M']()\n",
    "R_train, R_test = split_train_test_matrix(build_user_item_matrix(df), test_size=0.2)\n",
    "\n",
    "A = cosine_similarity(R_train.values)\n",
    "emb = spectral_embedding(A, n_components=2, random_state=42)\n",
    "labels = KMeans(n_clusters=50, random_state=42).fit_predict(emb)\n",
    "\n",
    "# Для каждого кластера находим топ-3 фильма:\n",
    "cluster_top3 = {}\n",
    "for c in np.unique(labels):\n",
    "    users_idx = np.where(labels == c)[0]\n",
    "    # берём подматрицу рейтингов этих пользователей\n",
    "    sub = R_train.iloc[users_idx]\n",
    "    # считаем средний рейтинг по каждому item (игнорируем нули)\n",
    "    mean_ratings = sub.replace(0, np.NaN).mean(axis=0).dropna()\n",
    "    top3_ids = mean_ratings.sort_values(ascending=False).head(3).index\n",
    "    top3_titles = movies_df.set_index('item_id').loc[top3_ids, 'title'].tolist()\n",
    "    cluster_top3[c] = top3_titles\n",
    "\n",
    "# Вычисляем центры кластеров в 2D:\n",
    "centers = []\n",
    "for c in np.unique(labels):\n",
    "    pts = emb[labels == c]\n",
    "    centers.append(pts.mean(axis=0))\n",
    "centers = np.vstack(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Рисуем scatter и аннотации:\n",
    "fig = plt.figure(figsize=(30,20))\n",
    "plt.scatter(emb[:,0], emb[:,1], c=labels, cmap='tab20', s=10, alpha=0.6)\n",
    "for c, (x,y) in enumerate(centers):\n",
    "    titles = cluster_top3[c]\n",
    "    text = \"\\n\".join(titles)\n",
    "    plt.text(x, y, text, fontsize=8, ha='center', va='center',\n",
    "             bbox=dict(boxstyle='round, pad=0.3', fc='white', alpha=0.7))\n",
    "plt.title(\"Spectral Clustering of Users with Top-3 Movies per Cluster\")\n",
    "plt.xlabel(\"Spectral Component 1\")\n",
    "plt.ylabel(\"Spectral Component 2\")\n",
    "plt.xlim([-0.002, 0.0015])\n",
    "plt.ylim([-0.002, 0.002])\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "fig.savefig('./results/top-3 movies in each cluster.png')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
